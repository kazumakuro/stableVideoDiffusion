{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazumakuro/stableVideoDiffusion/blob/main/stable_video_diffusion_img2vid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIuzds5LLPyC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkshing/notebooks/blob/main/stable_video_diffusion_img2vid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "# Stable Video Diffusion (image-to-video) Demo\n",
        "This notebook is the demo for the new image-to-video model, Stable Video Diffusion, from [Stability AI](https://stability.ai/) **on Colab free plan**.\n",
        "\n",
        "This was made by [mkshing](https://twitter.com/mk1stats).\n",
        "\n",
        "Visit the following links for the details of Stable Video Diffusion.\n",
        "* Codebase: https://github.com/Stability-AI/generative-models\n",
        "* HF:\n",
        " * SVD 1.0 (14 frames): https://huggingface.co/stabilityai/stable-video-diffusion-img2vid\n",
        " * SVD 1.0 (25 frames): https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt\n",
        " * SVD 1.1 (25 frames): https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1\n",
        "* LICENSE: [STABLE VIDEO DIFFUSION NON-COMMERCIAL COMMUNITY LICENSE AGREEMENT](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/blob/main/LICENSE)\n",
        "* Paper: https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets\n",
        "\n",
        "## Updates\n",
        "### 2024.2.4\n",
        "* Support [Stable Video Diffusion 1.1 Image-to-Video](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1)\n",
        "\n",
        "### 2023.11.27\n",
        "* Add the other hyper-parameters (`fps_id`, `motion_bucket_id`, `cond_aug`)\n",
        "\n",
        "![000000](https://user-images.githubusercontent.com/33302880/284800538-f856b437-aa1f-4675-ba40-03da3e953358.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "aaimSFWfLPgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83516fd-1463-4e61-e282-669f3de11539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun  6 02:03:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "fatal: destination path 'generative-models' already exists and is not an empty directory.\n",
            "--2024-06-06 02:03:11--  https://gist.githubusercontent.com/mkshing/4ad40699756d996ba6b3f7934e6ca532/raw/3f0094272c7a2bd3eb5f1a0db91bed582c9e8f01/requirements.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 746 [text/plain]\n",
            "Saving to: ‘requirements.txt.2’\n",
            "\n",
            "requirements.txt.2  100%[===================>]     746  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-06 02:03:11 (45.4 MB/s) - ‘requirements.txt.2’ saved [746/746]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Collecting clip@ git+https://github.com/openai/CLIP.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-5be8v2fg/clip_7ade5179c36f4f39bb577d17e4b329b1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-5be8v2fg/clip_7ade5179c36f4f39bb577d17e4b329b1\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: black==23.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (23.7.0)\n",
            "Requirement already satisfied: chardet==5.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (5.1.0)\n",
            "Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: fairscale>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.4.13)\n",
            "Requirement already satisfied: fire>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: invisible-watermark>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: kornia==0.6.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.6.9)\n",
            "Requirement already satisfied: matplotlib>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (3.9.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (8.4.0)\n",
            "Requirement already satisfied: ninja>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.1.1)\n",
            "Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.3.0)\n",
            "Requirement already satisfied: open-clip-torch>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.24.0)\n",
            "Requirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.6.0.66)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (10.3.0)\n",
            "Requirement already satisfied: pudb>=2022.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (2024.1)\n",
            "Requirement already satisfied: pytorch-lightning==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.0.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (1.11.4)\n",
            "Requirement already satisfied: streamlit>=0.73.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (1.35.0)\n",
            "Requirement already satisfied: tensorboardx==2.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (2.6)\n",
            "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.0.3)\n",
            "Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.12.1)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (2.0.2+cu118)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (0.6.1)\n",
            "Requirement already satisfied: torchmetrics>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (1.4.0.post0)\n",
            "Requirement already satisfied: torchvision>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (4.66.4)\n",
            "Requirement already satisfied: transformers==4.19.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (4.19.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (2.0.0)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from -r requirements.txt (line 36))\n",
            "  Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "Requirement already satisfied: wandb>=0.15.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (0.17.0)\n",
            "Requirement already satisfied: webdataset>=0.2.33 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.2.86)\n",
            "Requirement already satisfied: wheel>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (0.43.0)\n",
            "Requirement already satisfied: xformers>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (0.0.22)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r requirements.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r requirements.txt (line 2)) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.6.0.66->-r requirements.txt (line 17)) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.1->-r requirements.txt (line 21)) (4.12.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.1->-r requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardx==2.6->-r requirements.txt (line 25)) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->-r requirements.txt (line 30)) (2.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 28)) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 28)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 28)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r requirements.txt (line 28)) (3.1.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r requirements.txt (line 34)) (0.23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r requirements.txt (line 34)) (2024.5.15)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->-r requirements.txt (line 35)) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->-r requirements.txt (line 35)) (18.1.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->-r requirements.txt (line 4)) (6.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.5.0->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.5.0->-r requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark>=0.2.0->-r requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r requirements.txt (line 11)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r requirements.txt (line 11)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r requirements.txt (line 11)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.3.0->-r requirements.txt (line 15)) (4.9.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.20.0->-r requirements.txt (line 16)) (0.1.99)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->-r requirements.txt (line 18)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->-r requirements.txt (line 18)) (2024.1)\n",
            "Requirement already satisfied: urwid>=2.4 in /usr/local/lib/python3.10/dist-packages (from pudb>=2022.1.3->-r requirements.txt (line 20)) (2.6.12)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from pudb>=2022.1.3->-r requirements.txt (line 20)) (2.16.1)\n",
            "Requirement already satisfied: jedi<1,>=0.18 in /usr/local/lib/python3.10/dist-packages (from pudb>=2022.1.3->-r requirements.txt (line 20)) (0.19.1)\n",
            "Requirement already satisfied: urwid-readline in /usr/local/lib/python3.10/dist-packages (from pudb>=2022.1.3->-r requirements.txt (line 20)) (0.14)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (5.3.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r requirements.txt (line 24)) (4.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->-r requirements.txt (line 26)) (0.4.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r requirements.txt (line 37)) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r requirements.txt (line 37)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r requirements.txt (line 37)) (2.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r requirements.txt (line 37)) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r requirements.txt (line 37)) (67.7.2)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset>=0.2.33->-r requirements.txt (line 38)) (0.1.7)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (0.12.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec>=2023.6.0->-r requirements.txt (line 8)) (3.9.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.73.1->-r requirements.txt (line 24)) (4.0.11)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi<1,>=0.18->pudb>=2022.1.3->-r requirements.txt (line 20)) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->-r requirements.txt (line 28)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.1->-r requirements.txt (line 30)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.1->-r requirements.txt (line 30)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.1->-r requirements.txt (line 30)) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (3.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from urwid>=2.4->pudb>=2022.1.3->-r requirements.txt (line 20)) (0.2.13)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->-r requirements.txt (line 28)) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r requirements.txt (line 8)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r requirements.txt (line 8)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r requirements.txt (line 8)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r requirements.txt (line 8)) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.73.1->-r requirements.txt (line 24)) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.73.1->-r requirements.txt (line 24)) (0.1.2)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.1\n",
            "    Uninstalling urllib3-2.2.1:\n",
            "      Successfully uninstalled urllib3-2.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 4.33.0 requires urllib3~=2.0, but you have urllib3 1.26.18 which is incompatible.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1+cu118 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed urllib3-1.26.18\n",
            "Obtaining file:///content/generative-models\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sgm\n",
            "  Building editable for sgm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgm: filename=sgm-0.1.0-py3-none-any.whl size=29777 sha256=1a38b07904136229b340df72145a1e6f39c5b33a465b7e5fad3083cdd57e34fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wulbe49d/wheels/12/9b/27/03142f4dee9fa0a99f6c146eae81eb66e17b781145ecb05fa5\n",
            "Successfully built sgm\n",
            "Installing collected packages: sgm\n",
            "  Attempting uninstall: sgm\n",
            "    Found existing installation: sgm 0.1.0\n",
            "    Uninstalling sgm-0.1.0:\n",
            "      Successfully uninstalled sgm-0.1.0\n",
            "Successfully installed sgm-0.1.0\n",
            "Obtaining sdata from git+https://github.com/Stability-AI/datapipelines.git@main#egg=sdata\n",
            "  Updating ./src/sdata clone (to revision main)\n",
            "  Running command git fetch -q --tags\n",
            "  Running command git reset --hard -q 8bce77d147033b3a5285b6d45ee85f33866964fc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: sdata\n",
            "  Attempting uninstall: sdata\n",
            "    Found existing installation: sdata 0.0.1\n",
            "    Uninstalling sdata-0.0.1:\n",
            "      Successfully uninstalled sdata-0.0.1\n",
            "  Running setup.py develop for sdata\n",
            "Successfully installed sdata-0.0.1\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.33.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.17.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.17.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.3.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.1)\n",
            "Collecting urllib3~=2.0 (from gradio)\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.17.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.18\n",
            "    Uninstalling urllib3-1.26.18:\n",
            "      Successfully uninstalled urllib3-1.26.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1+cu118 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed urllib3-2.2.1\n"
          ]
        }
      ],
      "source": [
        "#@title Setup\n",
        "!nvidia-smi\n",
        "!git clone https://github.com/Stability-AI/generative-models.git\n",
        "# install required packages from pypi\n",
        "# !pip3 install -r generative-models/requirements/pt2.txt\n",
        "# manually install only necesarry packages for colab\n",
        "!wget https://gist.githubusercontent.com/mkshing/4ad40699756d996ba6b3f7934e6ca532/raw/3f0094272c7a2bd3eb5f1a0db91bed582c9e8f01/requirements.txt\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install -e generative-models\n",
        "!pip3 install -e git+https://github.com/Stability-AI/datapipelines.git@main#egg=sdata\n",
        "!pip3 install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mawwnzWX246N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b88966-c45e-4b73-9940-30a868d8c304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "#@title Login HuggingFace to download weights\n",
        "#@markdown Please make sure to fill in the form in the model cards and accept it.\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "# トークンを設定\n",
        "import os\n",
        "os.environ['HF_TOKEN'] = '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'\n",
        "\n",
        "# Hugging Face Hubにログイン\n",
        "from huggingface_hub import login\n",
        "login(token=os.getenv('HF_TOKEN'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zWlfaXvPbR1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "76b7467e-8e42-4a93-c006-201839ef3c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link '/content/scripts/util/detection/p_head_v1.npz': File exists\n",
            "ln: failed to create symbolic link '/content/scripts/util/detection/w_head_v1.npz': File exists\n"
          ]
        }
      ],
      "source": [
        "#@title Colab hack for SVD\n",
        "# !pip uninstall -y numpy\n",
        "# !pip install -U numpy\n",
        "!mkdir -p /content/scripts/util/detection\n",
        "!ln -s /content/generative-models/scripts/util/detection/p_head_v1.npz /content/scripts/util/detection/p_head_v1.npz\n",
        "!ln -s /content/generative-models/scripts/util/detection/w_head_v1.npz /content/scripts/util/detection/w_head_v1.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "v8O2yR3BLHv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4233a7-4846-43bf-dad8-f7c52eb81a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already downloaded\n"
          ]
        }
      ],
      "source": [
        "# @title Download weights\n",
        "import os\n",
        "import subprocess\n",
        "from huggingface_hub import hf_hub_download\n",
        "version = \"svd-xt\" #@param [\"svd\", \"svd-xt\", \"svd-xt-1-1\"]\n",
        "TYPE2PATH = {\n",
        "    \"svd\": [\"stabilityai/stable-video-diffusion-img2vid\", \"svd.safetensors\"],\n",
        "    \"svd-xt\": [\"stabilityai/stable-video-diffusion-img2vid-xt\", \"svd_xt.safetensors\"],\n",
        "    \"svd-xt-1-1\": [\"stabilityai/stable-video-diffusion-img2vid-xt-1-1\", \"svd_xt_1_1.safetensors\"],\n",
        "}\n",
        "repo_id, fname = TYPE2PATH[version]\n",
        "ckpt_dir = \"/content/checkpoints\"\n",
        "ckpt_path = os.path.join(ckpt_dir, fname)\n",
        "# @markdown This will take several minutes. <br>\n",
        "# @markdown **Reference:**\n",
        "# @markdown * `svd`: [stabilityai/stable-video-diffusion-img2vid](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid) for 14 frames generation\n",
        "# @markdown * `svd-xt`: [stabilityai/stable-video-diffusion-img2vid-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) for 25 frames generation\n",
        "# @markdown * `svd-xt-1-1`: [stabilityai/stable-video-diffusion-img2vid-xt-1-1](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1) for 25 frames generation with fixed conditioning at 6FPS and Motion Bucket Id 127\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "if os.path.exists(ckpt_path):\n",
        "  print(\"Already downloaded\")\n",
        "else:\n",
        "  hf_hub_download(\n",
        "      repo_id=repo_id,\n",
        "      filename=fname,\n",
        "      local_dir=ckpt_dir,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "9AZDrh-SUDt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64b9a21-72dd-43b5-9352-25e916a2daf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed `ckpt_path` to /content/checkpoints/svd_xt.safetensors\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n",
            "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n",
            "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Restored from /content/checkpoints/svd_xt.safetensors with 0 missing and 0 unexpected keys\n"
          ]
        }
      ],
      "source": [
        "#@title Load Model\n",
        "import sys\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"generative-models\")\n",
        "from sgm.util import default, instantiate_from_config\n",
        "from scripts.util.detection.nsfw_and_watermark_dectection import DeepFloydDataFiltering\n",
        "\n",
        "def load_model(\n",
        "    config: str,\n",
        "    device: str,\n",
        "    num_frames: int,\n",
        "    num_steps: int,\n",
        "    ckpt_path: str = None,\n",
        "):\n",
        "    config = OmegaConf.load(config)\n",
        "    config.model.params.conditioner_config.params.emb_models[\n",
        "        0\n",
        "    ].params.open_clip_embedding_config.params.init_device = device\n",
        "    config.model.params.sampler_config.params.num_steps = num_steps\n",
        "    config.model.params.sampler_config.params.guider_config.params.num_frames = (\n",
        "        num_frames\n",
        "    )\n",
        "    if ckpt_path is not None:\n",
        "        config.model.params.ckpt_path = ckpt_path\n",
        "        print(f\"Changed `ckpt_path` to {ckpt_path}\")\n",
        "    with torch.device(device):\n",
        "        model = instantiate_from_config(config.model).to(device).eval().requires_grad_(False)\n",
        "\n",
        "    filter = DeepFloydDataFiltering(verbose=False, device=device)\n",
        "    return model, filter\n",
        "\n",
        "\n",
        "if version == \"svd\":\n",
        "    num_frames = 14\n",
        "    num_steps = 25\n",
        "    # output_folder = default(output_folder, \"outputs/simple_video_sample/svd/\")\n",
        "    model_config = \"generative-models/scripts/sampling/configs/svd.yaml\"\n",
        "elif \"svd-xt\" in version:\n",
        "    num_frames = 25\n",
        "    num_steps = 30\n",
        "    # output_folder = default(output_folder, \"outputs/simple_video_sample/svd_xt/\")\n",
        "    model_config = \"generative-models/scripts/sampling/configs/svd_xt.yaml\"\n",
        "else:\n",
        "    raise ValueError(f\"Version {version} does not exist.\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, filter = load_model(\n",
        "    model_config,\n",
        "    device,\n",
        "    num_frames,\n",
        "    num_steps,\n",
        "    ckpt_path,\n",
        ")\n",
        "# move models expect unet to cpu\n",
        "model.conditioner.cpu()\n",
        "model.first_stage_model.cpu()\n",
        "# change the dtype of unet\n",
        "model.model.to(dtype=torch.float16)\n",
        "torch.cuda.empty_cache()\n",
        "model = model.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "x1-dnq0RT95O"
      },
      "outputs": [],
      "source": [
        "# @title Sampling function\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from einops import rearrange, repeat\n",
        "from fire import Fire\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "from sgm.inference.helpers import embed_watermark\n",
        "from sgm.util import default, instantiate_from_config\n",
        "\n",
        "\n",
        "def get_unique_embedder_keys_from_conditioner(conditioner):\n",
        "    return list(set([x.input_key for x in conditioner.embedders]))\n",
        "\n",
        "\n",
        "def get_batch(keys, value_dict, N, T, device, dtype=None):\n",
        "    batch = {}\n",
        "    batch_uc = {}\n",
        "\n",
        "    for key in keys:\n",
        "        if key == \"fps_id\":\n",
        "            batch[key] = (\n",
        "                torch.tensor([value_dict[\"fps_id\"]])\n",
        "                .to(device, dtype=dtype)\n",
        "                .repeat(int(math.prod(N)))\n",
        "            )\n",
        "        elif key == \"motion_bucket_id\":\n",
        "            batch[key] = (\n",
        "                torch.tensor([value_dict[\"motion_bucket_id\"]])\n",
        "                .to(device, dtype=dtype)\n",
        "                .repeat(int(math.prod(N)))\n",
        "            )\n",
        "        elif key == \"cond_aug\":\n",
        "            batch[key] = repeat(\n",
        "                torch.tensor([value_dict[\"cond_aug\"]]).to(device, dtype=dtype),\n",
        "                \"1 -> b\",\n",
        "                b=math.prod(N),\n",
        "            )\n",
        "        elif key == \"cond_frames\":\n",
        "            batch[key] = repeat(value_dict[\"cond_frames\"], \"1 ... -> b ...\", b=N[0])\n",
        "        elif key == \"cond_frames_without_noise\":\n",
        "            batch[key] = repeat(\n",
        "                value_dict[\"cond_frames_without_noise\"], \"1 ... -> b ...\", b=N[0]\n",
        "            )\n",
        "        else:\n",
        "            batch[key] = value_dict[key]\n",
        "\n",
        "    if T is not None:\n",
        "        batch[\"num_video_frames\"] = T\n",
        "\n",
        "    for key in batch.keys():\n",
        "        if key not in batch_uc and isinstance(batch[key], torch.Tensor):\n",
        "            batch_uc[key] = torch.clone(batch[key])\n",
        "    return batch, batch_uc\n",
        "\n",
        "\n",
        "\n",
        "def sample(\n",
        "    input_path: str = \"assets/test_image.png\",  # Can either be image file or folder with image files\n",
        "    resize_image: bool = False,\n",
        "    num_frames: Optional[int] = None,\n",
        "    num_steps: Optional[int] = None,\n",
        "    fps_id: int = 6,\n",
        "    motion_bucket_id: int = 127,\n",
        "    cond_aug: float = 0.02,\n",
        "    seed: int = 23,\n",
        "    decoding_t: int = 14,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
        "    device: str = \"cuda\",\n",
        "    output_folder: Optional[str] = \"/content/outputs\",\n",
        "    skip_filter: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Simple script to generate a single sample conditioned on an image `input_path` or multiple images, one for each\n",
        "    image file in folder `input_path`. If you run out of VRAM, try decreasing `decoding_t`.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    path = Path(input_path)\n",
        "    all_img_paths = []\n",
        "    if path.is_file():\n",
        "        if any([input_path.endswith(x) for x in [\"jpg\", \"jpeg\", \"png\"]]):\n",
        "            all_img_paths = [input_path]\n",
        "        else:\n",
        "            raise ValueError(\"Path is not valid image file.\")\n",
        "    elif path.is_dir():\n",
        "        all_img_paths = sorted(\n",
        "            [\n",
        "                f\n",
        "                for f in path.iterdir()\n",
        "                if f.is_file() and f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]\n",
        "            ]\n",
        "        )\n",
        "        if len(all_img_paths) == 0:\n",
        "            raise ValueError(\"Folder does not contain any images.\")\n",
        "    else:\n",
        "        raise ValueError\n",
        "    all_out_paths = []\n",
        "    for input_img_path in all_img_paths:\n",
        "        with Image.open(input_img_path) as image:\n",
        "            if image.mode == \"RGBA\":\n",
        "                image = image.convert(\"RGB\")\n",
        "            if resize_image and image.size != (1024, 576):\n",
        "                print(f\"Resizing {image.size} to (1024, 576)\")\n",
        "                image = TF.resize(TF.resize(image, 1024), (576, 1024))\n",
        "            w, h = image.size\n",
        "\n",
        "            if h % 64 != 0 or w % 64 != 0:\n",
        "                width, height = map(lambda x: x - x % 64, (w, h))\n",
        "                image = image.resize((width, height))\n",
        "                print(\n",
        "                    f\"WARNING: Your image is of size {h}x{w} which is not divisible by 64. We are resizing to {height}x{width}!\"\n",
        "                )\n",
        "\n",
        "            image = ToTensor()(image)\n",
        "            image = image * 2.0 - 1.0\n",
        "\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "        H, W = image.shape[2:]\n",
        "        assert image.shape[1] == 3\n",
        "        F = 8\n",
        "        C = 4\n",
        "        shape = (num_frames, C, H // F, W // F)\n",
        "        if (H, W) != (576, 1024):\n",
        "            print(\n",
        "                \"WARNING: The conditioning frame you provided is not 576x1024. This leads to suboptimal performance as model was only trained on 576x1024. Consider increasing `cond_aug`.\"\n",
        "            )\n",
        "        if motion_bucket_id > 255:\n",
        "            print(\n",
        "                \"WARNING: High motion bucket! This may lead to suboptimal performance.\"\n",
        "            )\n",
        "\n",
        "        if fps_id < 5:\n",
        "            print(\"WARNING: Small fps value! This may lead to suboptimal performance.\")\n",
        "\n",
        "        if fps_id > 30:\n",
        "            print(\"WARNING: Large fps value! This may lead to suboptimal performance.\")\n",
        "\n",
        "        value_dict = {}\n",
        "        value_dict[\"motion_bucket_id\"] = motion_bucket_id\n",
        "        value_dict[\"fps_id\"] = fps_id\n",
        "        value_dict[\"cond_aug\"] = cond_aug\n",
        "        value_dict[\"cond_frames_without_noise\"] = image\n",
        "        value_dict[\"cond_frames\"] = image + cond_aug * torch.randn_like(image)\n",
        "        value_dict[\"cond_aug\"] = cond_aug\n",
        "        # low vram mode\n",
        "        model.conditioner.cpu()\n",
        "        model.first_stage_model.cpu()\n",
        "        torch.cuda.empty_cache()\n",
        "        model.sampler.verbose = True\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with torch.autocast(device):\n",
        "                model.conditioner.to(device)\n",
        "                batch, batch_uc = get_batch(\n",
        "                    get_unique_embedder_keys_from_conditioner(model.conditioner),\n",
        "                    value_dict,\n",
        "                    [1, num_frames],\n",
        "                    T=num_frames,\n",
        "                    device=device,\n",
        "                )\n",
        "                c, uc = model.conditioner.get_unconditional_conditioning(\n",
        "                    batch,\n",
        "                    batch_uc=batch_uc,\n",
        "                    force_uc_zero_embeddings=[\n",
        "                        \"cond_frames\",\n",
        "                        \"cond_frames_without_noise\",\n",
        "                    ],\n",
        "                )\n",
        "                model.conditioner.cpu()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # from here, dtype is fp16\n",
        "                for k in [\"crossattn\", \"concat\"]:\n",
        "                    uc[k] = repeat(uc[k], \"b ... -> b t ...\", t=num_frames)\n",
        "                    uc[k] = rearrange(uc[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
        "                    c[k] = repeat(c[k], \"b ... -> b t ...\", t=num_frames)\n",
        "                    c[k] = rearrange(c[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
        "                for k in uc.keys():\n",
        "                    uc[k] = uc[k].to(dtype=torch.float16)\n",
        "                    c[k] = c[k].to(dtype=torch.float16)\n",
        "\n",
        "                randn = torch.randn(shape, device=device, dtype=torch.float16)\n",
        "\n",
        "                additional_model_inputs = {}\n",
        "                additional_model_inputs[\"image_only_indicator\"] = torch.zeros(\n",
        "                    2, num_frames\n",
        "                ).to(device, )\n",
        "                additional_model_inputs[\"num_video_frames\"] = batch[\"num_video_frames\"]\n",
        "\n",
        "                for k in additional_model_inputs:\n",
        "                    if isinstance(additional_model_inputs[k], torch.Tensor):\n",
        "                        additional_model_inputs[k] = additional_model_inputs[k].to(dtype=torch.float16)\n",
        "\n",
        "                def denoiser(input, sigma, c):\n",
        "                    return model.denoiser(\n",
        "                        model.model, input, sigma, c, **additional_model_inputs\n",
        "                    )\n",
        "\n",
        "                samples_z = model.sampler(denoiser, randn, cond=c, uc=uc)\n",
        "                samples_z.to(dtype=model.first_stage_model.dtype)\n",
        "                ##\n",
        "\n",
        "                model.en_and_decode_n_samples_a_time = decoding_t\n",
        "                model.first_stage_model.to(device)\n",
        "                samples_x = model.decode_first_stage(samples_z)\n",
        "                samples = torch.clamp((samples_x + 1.0) / 2.0, min=0.0, max=1.0)\n",
        "                model.first_stage_model.cpu()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                os.makedirs(output_folder, exist_ok=True)\n",
        "                base_count = len(glob(os.path.join(output_folder, \"*.mp4\")))\n",
        "                video_path = os.path.join(output_folder, f\"{base_count:06d}.mp4\")\n",
        "                writer = cv2.VideoWriter(\n",
        "                    video_path,\n",
        "                    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
        "                    fps_id + 1,\n",
        "                    (samples.shape[-1], samples.shape[-2]),\n",
        "                )\n",
        "\n",
        "                samples = embed_watermark(samples)\n",
        "                if not skip_filter:\n",
        "                    samples = filter(samples)\n",
        "                else:\n",
        "                    print(\"WARNING: You have disabled the NSFW/Watermark filter. Please do not expose unfiltered results in services or applications open to the public.\")\n",
        "                vid = (\n",
        "                    (rearrange(samples, \"t c h w -> t h w c\") * 255)\n",
        "                    .cpu()\n",
        "                    .numpy()\n",
        "                    .astype(np.uint8)\n",
        "                )\n",
        "                for frame in vid:\n",
        "                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "                    writer.write(frame)\n",
        "                writer.release()\n",
        "                all_out_paths.append(video_path)\n",
        "    return all_out_paths\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5MdVILPlMUDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "874f6aeb-0696-4cb3-8f42-8743c68daa2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://82ba86b0e5347d919d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://82ba86b0e5347d919d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Your image is of size 2273x1600 which is not divisible by 64. We are resizing to 2240x1600!\n",
            "WARNING: The conditioning frame you provided is not 576x1024. This leads to suboptimal performance as model was only trained on 576x1024. Consider increasing `cond_aug`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 521, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 276, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1513, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 832, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-7-fb3fbbbc57b1>\", line 17, in infer\n",
            "    output_paths = sample(\n",
            "  File \"<ipython-input-6-b54a611e3dac>\", line 171, in sample\n",
            "    c, uc = model.conditioner.get_unconditional_conditioning(\n",
            "  File \"/content/generative-models/sgm/modules/encoders/modules.py\", line 179, in get_unconditional_conditioning\n",
            "    c = self(batch_c, force_cond_zero_embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/encoders/modules.py\", line 132, in forward\n",
            "    emb_out = embedder(batch[embedder.input_key])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/encoders/modules.py\", line 1012, in forward\n",
            "    out = self.encoder.encode(vid[n * n_samples : (n + 1) * n_samples])\n",
            "  File \"/content/generative-models/sgm/models/autoencoder.py\", line 472, in encode\n",
            "    z = self.encoder(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/diffusionmodules/model.py\", line 584, in forward\n",
            "    h = self.down[i_level].block[i_block](hs[-1], temb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/diffusionmodules/model.py\", line 134, in forward\n",
            "    h = nonlinearity(h)\n",
            "  File \"/content/generative-models/sgm/modules/diffusionmodules/model.py\", line 49, in nonlinearity\n",
            "    return x * torch.sigmoid(x)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.71 GiB (GPU 0; 14.75 GiB total capacity; 13.72 GiB already allocated; 769.06 MiB free; 13.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Your image is of size 2273x1600 which is not divisible by 64. We are resizing to 2240x1600!\n",
            "WARNING: The conditioning frame you provided is not 576x1024. This leads to suboptimal performance as model was only trained on 576x1024. Consider increasing `cond_aug`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 521, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 276, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1513, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 832, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-7-fb3fbbbc57b1>\", line 17, in infer\n",
            "    output_paths = sample(\n",
            "  File \"<ipython-input-6-b54a611e3dac>\", line 171, in sample\n",
            "    c, uc = model.conditioner.get_unconditional_conditioning(\n",
            "  File \"/content/generative-models/sgm/modules/encoders/modules.py\", line 179, in get_unconditional_conditioning\n",
            "    c = self(batch_c, force_cond_zero_embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/encoders/modules.py\", line 132, in forward\n",
            "    emb_out = embedder(batch[embedder.input_key])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/encoders/modules.py\", line 1012, in forward\n",
            "    out = self.encoder.encode(vid[n * n_samples : (n + 1) * n_samples])\n",
            "  File \"/content/generative-models/sgm/models/autoencoder.py\", line 472, in encode\n",
            "    z = self.encoder(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/diffusionmodules/model.py\", line 584, in forward\n",
            "    h = self.down[i_level].block[i_block](hs[-1], temb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/generative-models/sgm/modules/diffusionmodules/model.py\", line 133, in forward\n",
            "    h = self.norm1(h)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\", line 273, in forward\n",
            "    return F.group_norm(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2530, in group_norm\n",
            "    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.71 GiB (GPU 0; 14.75 GiB total capacity; 13.82 GiB already allocated; 673.06 MiB free; 13.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ],
      "source": [
        "# @title Do the Run!\n",
        "# @markdown Generation takes about 10 mins for 25 frames on T4 (Colab free plan). Please be patient...\n",
        "# @markdown (V100 takes about 3 mins.)\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "\n",
        "def infer(input_path: str, resize_image: bool, n_frames: int, n_steps: int, seed: str, decoding_t: int, fps_id: int, motion_bucket_id: int, cond_aug: float, skip_filter: bool = False) -> str:\n",
        "  if seed == \"random\":\n",
        "    seed = random.randint(0, 2**32)\n",
        "  if version == \"svd-xt-1-1\":\n",
        "    if fps_id != 6:\n",
        "      print(\"[WARNING] svd-xt-1-1 was fine-tuned in fixed conditioning (`fps_id=6`, `motion_bucket_id=127`)! The performance may vary compared to SVD 1.0.\")\n",
        "    if motion_bucket_id != 127:\n",
        "      print(\"[WARNING] svd-xt-1-1 was fine-tuned in fixed conditioning (`fps_id=6`, `motion_bucket_id=127`)! The performance may vary compared to SVD 1.0.\")\n",
        "  seed = int(seed)\n",
        "  output_paths = sample(\n",
        "    input_path=input_path,\n",
        "    resize_image=resize_image,\n",
        "    num_frames=n_frames,\n",
        "    num_steps=n_steps,\n",
        "    fps_id=fps_id,\n",
        "    motion_bucket_id=motion_bucket_id,\n",
        "    cond_aug=cond_aug,\n",
        "    seed=seed,\n",
        "    decoding_t=decoding_t,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
        "    device=device,\n",
        "    skip_filter=skip_filter,\n",
        "  )\n",
        "  return output_paths[0]\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Column():\n",
        "    image = gr.Image(label=\"input image\", type=\"filepath\")\n",
        "    resize_image = gr.Checkbox(label=\"resize to optimal size\", value=True)\n",
        "    btn = gr.Button(\"Run\")\n",
        "    with gr.Accordion(label=\"Advanced options\", open=False):\n",
        "      n_frames = gr.Number(precision=0, label=\"number of frames\", value=num_frames)\n",
        "      n_steps = gr.Number(precision=0, label=\"number of steps\", value=num_steps)\n",
        "      seed = gr.Text(value=\"random\", label=\"seed (integer or 'random')\",)\n",
        "      decoding_t = gr.Number(precision=0, label=\"number of frames decoded at a time\", value=2)\n",
        "      fps_id = gr.Number(precision=0, label=\"frames per second\", value=6)\n",
        "      motion_bucket_id = gr.Number(precision=0, value=127, label=\"motion bucket id\")\n",
        "      cond_aug = gr.Number(label=\"condition augmentation factor\", value=0.02)\n",
        "      skip_filter = gr.Checkbox(value=False, label=\"skip nsfw/watermark filter\")\n",
        "  with gr.Column():\n",
        "    video_out = gr.Video(label=\"generated video\")\n",
        "  examples = [\n",
        "      [\"https://user-images.githubusercontent.com/33302880/284758167-367a25d8-8d7b-42d3-8391-6d82813c7b0f.png\"],\n",
        "  ]\n",
        "  inputs = [image, resize_image, n_frames, n_steps, seed, decoding_t, fps_id, motion_bucket_id, cond_aug, skip_filter]\n",
        "  outputs = [video_out]\n",
        "  btn.click(infer, inputs=inputs, outputs=outputs)\n",
        "  gr.Examples(examples=examples, inputs=inputs, outputs=outputs, fn=infer)\n",
        "  demo.queue().launch(debug=True, share=True, show_error=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}